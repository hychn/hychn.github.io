PURPOSE =====================================================================================
* General questions and simple, natural ideas that form the answer; these things fascinate and bring me great joy. Here are two such examples I encountered in the industry during the past three years.
* First, while classifying and segmenting satellite images, I explored the simple ideas: Image processing kernels that modifies (blur, outline, dilate) images, nonlinear-activation functions, gradient descent to adjust parameters of the kernels. It was very satisfying seeing such simple ideas work together to classify large areas of terrain accurately and much faster than annotation-by-hand. 
* Second, when handling complex input data with intrinsic structure, I learned to encode the input data to a latent space. Then, the input representation in the latent space was transformed with respect to the structure. These ideas allowed the AI to handle the complex input much more efficiently and observe the 3D robotic-arm’s and 3D protein’s structural properties when the input was a 2D image or a 1D protein sequence.

* How do you optimize a parameter that has no derivative? Does an optimum even exist? I encountered this key question many times, while finding: optimal model architecture for predicting satellite images, loss function for protein structure prediction, estimations of cost-to-go functions.
* Search and estimation by sampling are good, natural ideas that could answer this question. However, I was not satisfied with the naive and impractical exhaustive sampling. It took so long! I wish to study this key question in more detail with more specific questions: Does an optimal solution exist? What are its characteristics? What different types of sampling and estimation can we form? What is the consequence of using each? Are some better than others? Can we measure the quality of the estimation? What are the meaningful conditions/situations, where stronger conclusions can emerge?

WHY THIS PROGRAM =====================================================================================
* The CS PhD program at UIUC has 3 key characteristics that make it my top choice.
* First, I am very interested in the theoretical RL research by Professor Nan Jiang. His papers, 'Towards Hyperparameter-free Policy Selection for Offline Reinforcement Learning' and 'A Few Expert Queries Suffices for Sample-Efficient RL with Resets and Linear Value Approximation' provides ideas related to my key question of optimizing parameters without a derivative.
* Second, the course, 'Statistical Reinforcement Learning', will give me a solid background knowledge and jumpstart my research when I complete the novel theoretical research final project.
* Finally, I appreciate the guidance of the Artificial Intelligence Qualifying Exam Committee where I will present my research complemented with a background material tutorial. I heart-warmed by the committee's intent to encourage learning of fundamentals and diagnose weakness in my knowledge.

WHY YOU ARE QUALIFIED ==============================================================================
* I know that the program will be a challenging and require me to grow beyond my comfort zone. My experiences of overcoming difficulties in academics, industry, and self-study makes me well-prepared for this.

* For Academics, my Applied Mathematics and Computer Science master's degree gave me experience of applying logical and theoretical concepts. Courses such as Linear Algebra, Algebra, Analysis, Operations Research provide a solid background to understand AI ideas at a fundamental level. Analyzing protein structure using CNNs and persistent homology in my thesis, gave me interdisciplinary insight on how math and CS can complement each other. Finally, I really enjoyed the many hours thinking, meditating, and exploring theoretical concepts and questions.

* Working in the industry gave me valuable experience overcoming difficult problems and producing consistent results. Here are three examples.
  * First, working on segmentation of satellite images gave me the opportunity to read, implement from scratch, and benchmark papers such as U-Net and Deep Aggregate Net. The prototype and data analysis were used to win a major government contract for our company.
  * Second, while developing a semiconductor-robot monitoring prototype for SK Hynix, I combined Novel View Synthesis CNN algorithm with pose estimation to track and pose the robot arm. From a complex semiconductor monitoring video, the prototype extracted several key details: the positions of the robotic arm, the various nozzles attached to the arm, when the nozzle was spraying a solution or not.
  * Finally, predicting 3D structures from 1D protein sequences gave me the experience of managing and finishing a complex project. I combined various neural network architectures such as, LSTM, CNNs, and ESM language models embeddings into a single pipeline. Then I researched and experimented with distance, dihedral angle, frame-aligned point error functions. The resulting algorithm was much more stable, consistent, and quickly converging compared to starting baseline, Recurrent Geometric Networks. Over these three cases I gained value insights that helped me break through difficult challenges: have cautious optimism that a nice-simple solution exists, focus on key-measurable objectives, and work at a steady-consistent pace.

* Pursuing challenging independent research interests during my self-studies taught me discipline, motivation and persistence. Studying the AlphaGo Zero paper, I implemented a Monte Carlo Search Tree model-based RL to play variations of tic-tac-toe on longer length-to-win and boards. It was very challenging to get the initial prototypes to work on larger variations of the game; I carefully and patiently tried many different ideas. Eventually, reasonable success was found using: multi-step lookahead using model value estimation, augmentation of board inputs using rigid transformations, adjustments on rollout sample size depending on game depth, and many minor changes. Wanting to understand the RL the much better, I am currently studying the fundamentals of markov decision process programming and optimal control.

CLOSING NARRATIVE =====================================================================================
* AI is becoming more important and widely-used in the industry. By asking intriguing questions and finding simple, natural answers, I hope to contribute towards a more goal-aware and meaningful AI research. Doing this brings great joy and satisfaction in my heart.




# List of SCHOOLS
* Illinois Urbana Champaign
* Arizona State
* UMICH https://micde.umich.edu/methodology/optimization/
* Northwestern
* UNIFL https://www.eng.ufl.edu/ai-university/projects/foundations-of-ai/
* UNI Indiana https://luddy.indiana.edu/research/research-areas/ai-directory.html
* UNI KANSAS
* UNI Wisconsin Madison
* Ohio
* Colorado
* Nebraska
* UNC
* Georgia
* Texas
* California 
* Washington
* UNI Washington Mizou?
