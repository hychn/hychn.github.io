$\def\<={ \leq }$
$\def\>={ \geq }$
$\def\->{ \rightarrow}$


* Proofs from THE BOOK

# TODO
* GRE (take at home)
* PASSPORT
* Apply to 2-3 phD applied math programs with math letter of recommendations
* Proof of Funding

# Birth
* City of Birth: Pocheon/Seoul, Gyeonggi

# Address Contact
* 20 Changseon-Ro 131BEON-Gil
* Changseon-Myeon, Namhae-Gun
* South Gyeongsang
* 52453
* +1 8201022591479

# EDU
* Depauw 8-2010, 5-2014
* Mizzou 8-2016, 5-2019

# Recommendation
* Jan Segert
  * Mathematics Department, University of Missouri
  * professor, retired
  * Master's Thesis Supervisor
  * segertj@gmail.com
* Jianlin Cheng
  * Department of Electrical Engineering and Computer Science
  * Thompson Missouri Distinguished Professor/Director of Bio-ML Lab
  * Master's Thesis Supervisor
  * chengji@missouri.edu
* Ilsang Yoon
  * BIORCHESTRA
  * Chief Alliance Officer 
  * Senior Vice President at PharmCADD
  * isyoon@biorchestra.com

# STEPS
* Finish apply, SOP
* Get supplementary stuff
  * GRE, DuoLingo
* Study the RL field more, read the papers of professors
* Email professors, that request
  * Asking for guidance on which topics to study
    * https://arxiv.org/pdf/2203.12139.pdf
    * Some terms familiar, some terms new
    * ELBO, KL divergence

# List of Schools/Deadline

* For all these schools, check research, and requirements, and write phd
* How about you contact these professors and then see if they have openings in their lab to decide wether to apply or not?

* [UNI Indiana](https://iugraduate2023.liaisoncas.com/applicant-ux/#/login) Dec 15
  * [faculty](https://luddy.indiana.edu/research/research-areas/ai-directory.html)
  * SOP why this school is for you
  * RL [Qin Zhang](https://homes.luddy.indiana.edu/qzhangcs)
    * Collaborative Learning with Limited Interaction: Tight Bounds for Distributed Exploration in Multi-Armed Bandits
  * RL [Roni Khardon](https://cgi.luddy.indiana.edu/~rkhardon/publications.php)
    * Approximate Inference for Stochastic Planning in Factored Spaces
  * RL Robots [Lantao Liu](https://vail.sice.indiana.edu/index.html)

* [Washington University in St. Louis](https://gradadmit.wustl.edu/apply/?sr=4503835c-76a0-44d8-b086-00f19e2bb810)
  * Dec 15 $75
    * Letter Rec
    * SOP
    * Fellowship essay
    * Research Experience Contact
  * [Program Info](https://gradadmit.wustl.edu/apply/?sr=4503835c-76a0-44d8-b086-00f19e2bb810)
    * If you join the PhD program at Washington University, one of the courses you take in your first semester is Introduction to Graduate Study in CSE. As part of this course, you will do two one-month rotations in the research groups of faculty members who are recruiting graduate students. 
    * The rotation model does not preclude students from initiating discussions with faculty whose group they really want to join prior to joining WashU, but it offers the opportunity to be exposed to other research areas and approaches and to interact with potential research advisers before finalizing a commitment.
  * [Deadlines/info](https://engineering.wustl.edu/academics/graduate-admissions/application-checklist.html)
  * [Faculty](https://machinelearning.wustl.edu/faculty/)
    * [William Yeoh](https://sites.wustl.edu/wyeoh/research/)
      * Stochastic Goal Recognition Design Problems with Suboptimal Agents
        * Goal Recognition Design (GRD) problems identify the minimum number of environmental modifications aiming to force an interacting agent to reveal its goal as early as possible. 
          * Extending the stochastic goal recognition design framework by supporting suboptimal agents in cases where an observer has either full or partial observability
          * Presenting methods to evaluate the ambiguity of the model under these assumptions
    * [Brendan Juba](https://www.cse.wustl.edu/~bjuba/papers/index.html)
      * Learning Probably Approximately Complete and Safe Action Models for Stochastic Worlds
    * [Roman Garnett](https://www.cse.wustl.edu/~garnett/)
      * Automated Model Selection with Bayesian Quadrature
        * We present a novel technique for tailoring Bayesian quadrature (BQ) to model selection. The state-of-the-art for comparing the evidence of multiple models relies on Monte Carlo methods, which converge slowly and are unreliable for com- putationally expensive models. Although previ- ous research has shown that BQ offers sample efficiency superior to Monte Carlo in computing the evidence of an individual model, applying BQ directly to model comparison may waste computa- tion producing an overly-accurate estimate for the evidence of a clearly poor model. 

* [Georgia Institute of Technology](https://grad.gatech.edu/preparing-your-application) Dec 15
  * [Requirements](https://www.cc.gatech.edu/phd-cs-admissions-requirements)
  * [Faculty](https://cse.gatech.edu/content/artificial-intelligence-and-machine-learning)
    * https://ml.gatech.edu/people/faculty/phdprogramfaculty
    * [Florian Schäfer](https://f-t-s.github.io/) CONTACT
      * Robust Reinforcement Learning: A Constrained Game-theoretic Approach
    * [Yongxin Chen](https://yongxin.ae.gatech.edu/) CONTACT
      * Improved analysis for a proximal algorithm for sampling
    * [Panagiotis Tsiotras](https://dcsl.gatech.edu/research/autonomous-vehicle-learning.html)
    * [Yunan Luo](https://faculty.cc.gatech.edu/~yunan/)
      * ECNet is an evolutionary context-integrated deep learning framework for protein engineering

* [University of Texas at Austin](http://goapplytexas.org/)
  *  Additionally, applicants are exempt from the requirement if they possess a bachelor’s degree from a U.S. institution or a qualifying country. 
  * Letters of Rec, Statement of Purpose
  * [Info](https://www.cs.utexas.edu/graduate/prospective-students/apply) Dec 15
  * [Faculty](https://ml.utexas.edu/research-areas/faculty/reinforcement-learning)
  * [Qiang Liu](https://www.cs.utexas.edu/~lqiang/)
    * Action-depedent Control Variates for Policy Optimization via Stein's Identity
      * Motivated by the Stein's identity, our method extends the previous control variate methods used in REINFORCE and advantage actor-critic by introducing more general action-dependent baseline functions. 
  * [Peter Stone](https://www.cs.utexas.edu/~pstone/students.shtml)
    * Lucid Dreaming for Experience Replay: Refreshing Past States with the Current Policy
      * Experience replay (ER) improves the data efficiency of off-policy reinforcement learning (RL) algorithms by allowing an
      agent to store and reuse its past experiences in a replay buffer. While many techniques have been proposed to enhance ER
      by biasing how experiences are sampled from the buffer, thus far they have not considered strategies for refreshing
      experiences inside the buffer

* [Uni of Nebraska Lincoln] Jan 15
  * [Requirements](https://computing.unl.edu/graduate-admission-requirements/)
  * No gre, no english requirement
  * Hau Chan
    * [Monotone k-submodular secretary problems: Cardinality and knapsack constraints](https://www.sciencedirect.com/science/article/abs/pii/S0304397522002079?via%3Dihub)
    * [background reference](https://arxiv.org/pdf/1409.1399.pdf)
    * request pdf
    * DEF submodular $f(S)+f(T)\>= f(S\cap T) + F(S\cup T)$
      * U be a set, for $S,T \subseteq U$
      * $f : 2^U \-> \mathbb{R}$
    * [Adversarial Blocking Bandits](https://proceedings.neurips.cc/paper/2020/file/5cc3749a6e56ef6d656735dff9176074-Paper.pdf)
      * To complement our result, we show that a greedy algorithm
      that plays the best available arm at each round provides an approximation guarantee.
  * Leen-Kiat Soh
    * [Scalable Decision-Theoretic Planning in Open and Typed Multiagent Systems](https://ojs.aaai.org/index.php/AAAI/article/download/6200/6056)
      * Theoretical analyses establish the
      number of agents to model in order to achieve acceptable
      worst case bounds on extrapolation error, as well as regret
      bounds on the agent’s utility from modeling only some neigh-
      bors. 
  * https://cse.unl.edu/~qyao/#opportunity



# DONE  =================================================================

* [Illinois Urbana Champaign](https://choose.illinois.edu/apply/) Dec 15
  * TODO: Copy of passport
  * [Nan Jian](https://nanjiang.cs.illinois.edu/) CONTACT
  * [Matus Telgarsky](http://mjt.cs.illinois.edu/)
  * [Katie Driggs-Campbell](https://cs.illinois.edu/about/people/faculty/krdc)
  * [Kris K Hauser](https://cs.illinois.edu/about/people/faculty/kkhauser)
  * [Jian Peng](https://cs.illinois.edu/about/people/faculty/jianpeng)


* [University of Kansas](https://gograd.ku.edu/apply/)
  * TODO: Copy of passport/ Textbooks used
  * Math Phd Applied
  * stats, markov chain [Joonha Park](http://people.ku.edu/~j139p002/)
  * statistics [Zsolt Talata](https://talata.ku.edu/cv.html)
  * CS/AI RL control [Morteza Hashemi](https://hashemi.ku.edu/)

* [Arizona State](https://webapp4.asu.edu/dgsadmissions/logout) Dec 1
  * TODO: SOP
  * Faculty, SOP identify two or three ASU faculty with matching research interests. 
    * [Faculty list](https://scai.engineering.asu.edu/computer-science-and-engineering-faculty)
    * [Subbarao Kambhampati](https://search.asu.edu/profile/95646) [web2](https://yochan-lab.github.io/papers/)
      * Why Did You Do That? Generalizing Causal Link Explanations to Fully Observable Non-Deterministic Planning Problems
      * Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)
    * [Siddharth Srivastava](https://www.public.asu.edu/~ssriva43/)
      * Learning Dynamic Abstract Representations for Sample-Efficient Reinforcement Learning.
    * [Dimitri Bertsekas](https://search.asu.edu/profile/3410924)
      * 'ExpertRNA: A new framework for RNA structure prediction'
    * bio informatics [Heewook Lee](https://search.asu.edu/profile/3505050)
    * bio informatics [Stephanie Forrest](https://search.asu.edu/profile/3182641)
  * Program
    * [ASU program](https://degrees.apps.asu.edu/masters-phd/major/ASU00/ESCOMSCPHD/computer-science-phd?init=false&nopassive=true)
    * [ASU handbook](https://scai.engineering.asu.edu/wp-content/uploads/2022/08/PHD-CS-Handbook-2022-2023Publish.pdf)
      * Comprehensive exam, show mastered the knowledge to conduct research in specialization
      * Proposal exam, mastered the research methods to identify, formulate, and plan research in specialization

* [Ohio State](https://delegated.osu.edu/psp/csosuda/EMPLOYEE/CAMP/c/OAD_GEA.OAD_GEA_NUR_APL.GBL?) Dec 1
  * id: yechanhong92
  * TODO: SOP, faculty names
  * [Faculty](https://cse.osu.edu/research/artificial-intelligence)
    * [Andrew Perrault](https://aperrault.github.io/publications/)
      * 'Normality-Guided Distributional Reinforcement Learning for Continuous Control'
        * We propose a different idea, leveraging the features of the learned distribution to estimate whether a state is sufficiently visited or not.
          * Sampling enough
    * [Ness B. Shroff](http://newslab.ece.ohio-state.edu/for%20students/index.html)
      * 'Optimal Sampling for Data Freshness: Unreliable Transmissions with Random Two-way Delay'
        *  optimal sampling strategy that minimizes the long-term average estimation error
  * Program
    * Direct PhD track
    * Coursework (competant and knowledgeable on fundamental principles of cs) 
    * and research
    * new qualifying process, take time to build the basics and faculty research assessment
  * Course
    * STAT 7620 Elements of Statistical Learning, interdisciplinary final project to apply the ideas

* [Uni Wisconsin Madison](https://apply.grad.wisc.edu/Account/Login?ReturnUrl=%2f) Dec 15
  * https://www.cs.wisc.edu/graduate/graduate-admissions-faq/
  * faculty
    * RL [Josiah Hanna](https://pages.cs.wisc.edu/~jphanna/publications.html)
      * 'Importance Sampling in Reinforcement Learning with an Estimated Behavior Policy'
        * By replacing behavior policy action probabilities with maximum likelihood estimates from observed data, reduce variance due to sampling error.
    * RL [Xiaojin Zhu](https://pages.cs.wisc.edu/~jerryzhu/research.html)
      * 'The Sample Complexity of Teaching-by-Reinforcement on Q-Learning'
        * characterize the sample complexity of teaching for different constraints in constructing teaching sequence
        * I raelly like this style of exploring consequences
    * statistics: [Miaoyan Wang](https://pages.stat.wisc.edu/~miaoyan/people.html)
    * bio [Vikas Singh](https://www.biostat.wisc.edu/~vsingh/)
    * [Ilias Diakonikolas](http://www.iliasdiakonikolas.org/)
    * statistics: [Garvesh Raskutti](https://pages.cs.wisc.edu/~raskutti/publication.html)
    * Daifeng Wang
    
  * TODO: add Robert Nowak
  * SOP why this school is for you
    * faculty research
    * courses
        * CS761 Mathematical Foundations of Machine Learning
          * foundations fo statistics, final project to make small contribution to jumpstart the research process.
    * program characteristic
      * Well balanced
      * breadth requirement, take courese, passing qualifying examination
        * Artificial Intelligence: 532, 534, 540, 545, 731, 760, 761, 766, 769
        * Bioinformatics: 576,776
      * depth requirement: preliminary examination



* [University of Colorado Boulder](https://grad.apply.colorado.edu/account/login)
  * [Statement of Purpose](https://www.colorado.edu/cs/admissions/graduate-admissions/how-apply)
    * Colorado doesn't have a seperate section for indicating interest to program so you need to be really clear in this section.
    * Section headers

  * [recruiting](https://www.colorado.edu/cs/admissions/graduate-admissions/see-who-recruiting-fall-2023)
  * [requirements](https://www.colorado.edu/cs/academics/graduate-programs/doctor-philosophy/degree-requirements)
  * RL Control Systems [Majid Zamani](https://www.hyconsys.com/publications.html)
  * RL [Lijun Chen](https://spot.colorado.edu/~lich1539/)
  * RL [Ashutosh Trivedi](https://astrivedi.github.io/www/pubs.html)
  * SOP why this school is for you, just list of professors
    * Professor Lijun Chen's research, 'Incentivized Exploration for Multi-Armed Bandits under Reward Drift', provides ideas related to my key question of qualifying different types of sampling; the paper explores a compensation scheme for UCB, e-Greedy, and Thompson sampling algorithms and demonstrates it's effectiveness by show the regret is similar to the compensation. I really appreciated the style of the paper where the theory was backed up with numerical experiments.
    * Professor Majid Zamani's research, 'Compositional construction of finite MDPs for large-scale stochastic switched systems: A dissipativity approach', constructs an estimation and establishes an upper bound for the error. I am very interested in these types of techniques of simplifying a more complex system and qualifying the simplication.
    * I am also intrested in the statistical machine learning research from the mathematics department; professor Jem Corcoran's research on using importance sampling to manage rare event probabilities partially answers my key questions on how sampling and computational effectiveness.
    * I am looking forward to taking required coursework such as Probabilistic Models of Human and Machine Learning mathematical background and plenty of practical experience neccesary to start research.


