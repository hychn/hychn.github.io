<!DOCTYPE html><html><head><title>Application</title><meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" /><meta http-equiv="Pragma" content="no-cache" /><meta http-equiv="Expires" content="0" /><link rel = "stylesheet" type = "text/css" href = "https://hychn.github.io/style.css" /><meta name="viewport" content="width=device-width, initial-scale=1" /><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://hychn.github.io/tbl_contents.js"></script> </head> <body style="background-color:white;"> <div class="top"><button onclick="toggle_show()">Table of Contents</button> <button onclick="toggle_show_spoiler()">Toggle Spoiler</button>  <button onclick="scroll_bottom()">GOTO END</button> <div id="toc_frame"> <div id="toc"></div> </div> </div>   <div id="contents">
<p>\(\def\ < ={ \leq }\)
\(\def\ > ={ \geq }\)
\(\def\- > { \rightarrow}\)</p>

<ul>
<li>Proofs from THE BOOK</li>
</ul>

<h1>TODO</h1>

<ul>
<li>Duolingo</li>
<li>PASSPORT</li>
<li>Apply to 2-3 phD applied math programs with math letter of recommendations</li>
<li>Proof of Funding</li>
</ul>

<h1>Birth</h1>

<ul>
<li>City of Birth: Pocheon/Seoul, Gyeonggi</li>
</ul>

<h1>Address Contact</h1>

<ul>
<li>20 Changseon-Ro 131BEON-Gil</li>
<li>Changseon-Myeon, Namhae-Gun</li>
<li>South Gyeongsang</li>
<li>52453</li>
<li>+1 8201022591479</li>
</ul>

<h1>EDU</h1>

<ul>
<li>Depauw 8-2010, 5-2014</li>
<li>Mizzou 8-2016, 5-2019</li>
</ul>

<h1>Recommendation</h1>

<ul>
<li>Jan Segert
<ul>
<li>Mathematics Department, University of Missouri</li>
<li>professor, retired</li>
<li>Master's Thesis Supervisor</li>
<li>segertj@gmail.com</li>
</ul></li>
<li>Jianlin Cheng
<ul>
<li>Department of Electrical Engineering and Computer Science</li>
<li>Thompson Missouri Distinguished Professor/Director of Bio-ML Lab</li>
<li>Master's Thesis Supervisor</li>
<li>chengji@missouri.edu</li>
</ul></li>
<li>Ilsang Yoon
<ul>
<li>BIORCHESTRA</li>
<li>Chief Alliance Officer </li>
<li>Senior Vice President at PharmCADD</li>
<li>isyoon@biorchestra.com</li>
</ul></li>
</ul>

<h1>STEPS</h1>

<ul>
<li>Finish apply, SOP</li>
<li>Get supplementary stuff
<ul>
<li>GRE, DuoLingo</li>
</ul></li>
<li>Study the RL field more, read the papers of professors</li>
<li>Email professors, that request
<ul>
<li>Asking for guidance on which topics to study
<ul>
<li>https://arxiv.org/pdf/2203.12139.pdf</li>
<li>Some terms familiar, some terms new</li>
<li>ELBO, KL divergence</li>
</ul></li>
</ul></li>
</ul>

<h1>List of Schools/Deadline</h1>

<ul>
<li>For all these schools, check research, and requirements, and write phd</li>
<li><p>How about you contact these professors and then see if they have openings in their lab to decide wether to apply or not?</p></li>
<li><p><a href="https://iugraduate2023.liaisoncas.com/applicant-ux/#/login">UNI Indiana</a> Dec 15</p>

<ul>
<li><a href="https://luddy.indiana.edu/research/research-areas/ai-directory.html">faculty</a></li>
<li>SOP why this school is for you</li>
<li>RL <a href="https://homes.luddy.indiana.edu/qzhangcs">Qin Zhang</a> CONTACT
<ul>
<li><a href="https://homes.luddy.indiana.edu/qzhangcs/papers/dist-bandits-full.pdf">Collaborative Learning with Limited Interaction: Tight Bounds for Distributed Exploration in Multi-Armed Bandits</a>
<ul>
<li>Distributed system, improve sampling by using multiple agents </li>
<li>making leanring scalable</li>
<li>Contributions
<ul>
<li>??? It is very hard to understand these, let me read the paper</li>
<li>Almost tight round-speedup tradeoffs for fixed-time</li>
</ul></li>
</ul></li>
</ul></li>
<li>RL <a href="https://cgi.luddy.indiana.edu/~rkhardon/publications.php">Roni Khardon</a>
<ul>
<li><a href="https://cgi.luddy.indiana.edu/~rkhardon/PUB/aistats2021-DLMsGP.pdf">Direct Loss Minimization for Sparse Gaussian Processes</a>
<ul>
<li>Bayesian posterior \(p(\theta |x) = \dfrac{p(x|\theta)}{p(x)} p(\theta)\) parameter given evidence
<ul>
<li>where \(p(x) = \int p(x|\theta) p(\theta) d\theta\)</li>
</ul></li>
<li><a href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf">Variational inference</a></li>
<li><a href="http://mi.eng.cam.ac.uk/~mjfg/local/4F10.old/lect10.pdf">Bayesian Network and Message Passing</a>
<ul>
<li>Message Passing
<ul>
<li>Trees where each node has one parent</li>
</ul></li>
</ul></li>
<li>[Neuro-Dynamic Programming Bertsekas DP Tsitskilis</li>
</ul></li>
<li><a href="https://arxiv.org/pdf/2203.12139.pdf">Approximate Inference for Stochastic Planning in Factored Spaces</a>
<ul>
<li>Belief Propagation
<ul>
<li>Motivation: Find marginal distributions \(p_{X_i}(x_i)a = \sum\)</li>
</ul></li>
</ul></li>
</ul></li>
<li>RL Robots <a href="https://vail.sice.indiana.edu/index.html">Lantao Liu</a>
<ul>
<li><a href="https://arxiv.org/pdf/2210.08672.pdf">Decision-Making Among Bounded Rational Agents</a>
<ul>
<li>Computational constraints during the modeling process</li>
<li>Naturally reason about sub-optimal behaviors</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>[Uni of Nebraska Lincoln] Jan 15</p>

<ul>
<li><a href="https://computing.unl.edu/graduate-admission-requirements/">Requirements</a></li>
<li>No gre, no english requirement</li>
<li>Hau Chan, I don think this professor fits well TBH
<ul>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0304397522002079?via%3Dihub">Monotone k-submodular secretary problems: Cardinality and knapsack constraints</a></li>
<li><a href="https://arxiv.org/pdf/1409.1399.pdf">background reference</a></li>
<li>request pdf</li>
<li>DEF submodular \(f(S)+f(T)\ > = f(S\cap T) + F(S\cup T)\)
<ul>
<li>U be a set, for \(S,T \subseteq U\)</li>
<li>\(f : 2^U \- >  \mathbb{R}\)</li>
</ul></li>
<li><a href="https://proceedings.neurips.cc/paper/2020/file/5cc3749a6e56ef6d656735dff9176074-Paper.pdf">Adversarial Blocking Bandits</a>
<ul>
<li>To complement our result, we show that a greedy algorithm
that plays the best available arm at each round provides an approximation guarantee.</li>
</ul></li>
</ul></li>
<li>Leen-Kiat Soh
<ul>
<li><a href="https://ojs.aaai.org/index.php/AAAI/article/download/6200/6056">Scalable Decision-Theoretic Planning in Open and Typed Multiagent Systems</a>
<ul>
<li>Theoretical analyses establish the number of agents to model in order to achieve acceptable worst case bounds on extrapolation error, as well as regret bounds on the agent’s utility from modeling only some neighbors. </li>
</ul></li>
</ul></li>
<li>https://cse.unl.edu/~qyao/#opportunity</li>
</ul></li>
<li><p><a href="https://gradadmit.wustl.edu/apply/?sr=4503835c-76a0-44d8-b086-00f19e2bb810">Washington University in St. Louis</a></p>

<ul>
<li>Dec 15 \(7\)
<ul>
<li>Letter Rec</li>
<li>SOP</li>
<li>Fellowship essay</li>
<li>Research Experience Contact</li>
</ul></li>
<li><a href="https://gradadmit.wustl.edu/apply/?sr=4503835c-76a0-44d8-b086-00f19e2bb810">Program Info</a>
<ul>
<li>If you join the PhD program at Washington University, one of the courses you take in your first semester is Introduction to Graduate Study in CSE. As part of this course, you will do two one-month rotations in the research groups of faculty members who are recruiting graduate students. </li>
<li>The rotation model does not preclude students from initiating discussions with faculty whose group they really want to join prior to joining WashU, but it offers the opportunity to be exposed to other research areas and approaches and to interact with potential research advisers before finalizing a commitment.</li>
</ul></li>
<li><a href="https://engineering.wustl.edu/academics/graduate-admissions/application-checklist.html">Deadlines/info</a></li>
<li><a href="https://machinelearning.wustl.edu/faculty/">Faculty</a>
<ul>
<li><a href="https://sites.wustl.edu/wyeoh/research/">William Yeoh</a>
<ul>
<li>Stochastic Goal Recognition Design Problems with Suboptimal Agents
<ul>
<li>Goal Recognition Design (GRD) problems identify the minimum number of environmental modifications aiming to force an interacting agent to reveal its goal as early as possible. 
<ul>
<li>Extending the stochastic goal recognition design framework by supporting suboptimal agents in cases where an observer has either full or partial observability</li>
<li>Presenting methods to evaluate the ambiguity of the model under these assumptions</li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="https://www.cse.wustl.edu/~bjuba/papers/index.html">Brendan Juba</a>
<ul>
<li>Learning Probably Approximately Complete and Safe Action Models for Stochastic Worlds</li>
</ul></li>
<li><a href="https://www.cse.wustl.edu/~garnett/">Roman Garnett</a>
<ul>
<li>Automated Model Selection with Bayesian Quadrature
<ul>
<li>We present a novel technique for tailoring Bayesian quadrature (BQ) to model selection. The state-of-the-art for comparing the evidence of multiple models relies on Monte Carlo methods, which converge slowly and are unreliable for com- putationally expensive models. Although previ- ous research has shown that BQ offers sample efficiency superior to Monte Carlo in computing the evidence of an individual model, applying BQ directly to model comparison may waste computa- tion producing an overly-accurate estimate for the evidence of a clearly poor model. </li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><p><a href="https://grad.gatech.edu/preparing-your-application">Georgia Institute of Technology</a> Dec 15</p>

<ul>
<li><a href="https://www.cc.gatech.edu/phd-cs-admissions-requirements">Requirements</a></li>
<li><a href="https://cse.gatech.edu/content/artificial-intelligence-and-machine-learning">Faculty</a>
<ul>
<li>https://ml.gatech.edu/people/faculty/phdprogramfaculty</li>
<li><a href="https://f-t-s.github.io/">Florian Schäfer</a> CONTACT
<ul>
<li>Robust Reinforcement Learning: A Constrained Game-theoretic Approach</li>
</ul></li>
<li><a href="https://yongxin.ae.gatech.edu/">Yongxin Chen</a> CONTACT
<ul>
<li>Improved analysis for a proximal algorithm for sampling</li>
</ul></li>
<li><a href="https://dcsl.gatech.edu/research/autonomous-vehicle-learning.html">Panagiotis Tsiotras</a></li>
<li><a href="https://faculty.cc.gatech.edu/~yunan/">Yunan Luo</a>
<ul>
<li>ECNet is an evolutionary context-integrated deep learning framework for protein engineering</li>
</ul></li>
</ul></li>
</ul></li>
</ul>

<h1>SOP DONE ========================================================</h1>

<ul>
<li><a href="http://goapplytexas.org/">University of Texas at Austin</a> Dec 15
<ul>
<li>SOP DONE</li>
<li>Additionally, applicants are exempt from the requirement if they possess a bachelor’s degree from a U.S. institution or a qualifying country. </li>
<li>Letters of Rec, Statement of Purpose</li>
<li><a href="https://www.cs.utexas.edu/graduate/prospective-students/apply">Info</a></li>
<li><a href="https://ml.utexas.edu/research-areas/faculty/reinforcement-learning">Faculty</a></li>
<li>Importance sampling: monte carlo method for evaluating properties of a particular distribution</li>
<li><a href="https://www.cs.utexas.edu/~lqiang/">Qiang Liu</a>
<ul>
<li><a href="https://arxiv.org/pdf/1810.12429.pdf">Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation</a></li>
<li><a href="https://arxiv.org/pdf/2209.00865.pdf">Diffusion-based Molecule Generation with Informative Prior Bridges</a>
<ul>
<li>Applications of mathematics and AI to generate high-quality and realistic molecules that respect prior information.</li>
</ul></li>
</ul></li>
<li><a href="https://www.cs.utexas.edu/~pstone/students.shtml">Peter Stone</a>
<ul>
<li><a href="https://www.cs.utexas.edu/~pstone/Papers/bib2html-links/NCAA21-Du.pdf">Lucid Dreaming for Experience Replay: Refreshing Past States with the Current Policy</a>
<ul>
<li>Experience replay (ER) improves the data efficiency of off-policy reinforcement learning (RL) algorithms by allowing an agent to store and reuse its past experiences in a replay buffer. While many techniques have been proposed to enhance ER by biasing how experiences are sampled from the buffer, thus far they have not considered strategies for refreshing experiences inside the buffer</li>
<li>LIiDER algorithm (we could try this for gomoku to make it less data hungry)
<ul>
<li>1 Lider moves agent back to a past state</li>
<li>2 Lider lets agent follow its current policy</li>
<li>3 stores and reuses new experience if it turned out better</li>
</ul></li>
<li>how to sample experiences</li>
</ul></li>
</ul></li>
<li>Program
<ul>
<li>Emphasis and encouragement focus on research
<ul>
<li>First semester Research Course</li>
<li>Find advisor during the first year</li>
</ul></li>
<li>C S 364M. Principles of Machine Learning II.</li>
<li>C S 394R. Reinforcement Learning: Theory and Practice.</li>
<li>C S 383D. Numerical Analysis: Interpolation, Approximation, Quadrature, and Differential Equations.</li>
<li>C S 388J. Optimization.</li>
</ul></li>
</ul></li>
</ul>

<h1>DONE  =================================================================</h1>

<ul>
<li><p><a href="https://choose.illinois.edu/apply/">Illinois Urbana Champaign</a> Dec 15</p>

<ul>
<li>TODO: Copy of passport</li>
<li><a href="https://nanjiang.cs.illinois.edu/">Nan Jian</a> CONTACT</li>
<li><a href="http://mjt.cs.illinois.edu/">Matus Telgarsky</a></li>
<li><a href="https://cs.illinois.edu/about/people/faculty/krdc">Katie Driggs-Campbell</a></li>
<li><a href="https://cs.illinois.edu/about/people/faculty/kkhauser">Kris K Hauser</a></li>
<li><a href="https://cs.illinois.edu/about/people/faculty/jianpeng">Jian Peng</a></li>
</ul></li>
<li><p><a href="https://gograd.ku.edu/apply/">University of Kansas</a> Jan 5</p>

<ul>
<li>TODO: Copy of passport</li>
<li>Math Phd Applied</li>
<li>stats, markov chain <a href="http://people.ku.edu/~j139p002/">Joonha Park</a></li>
<li>statistics <a href="https://talata.ku.edu/cv.html">Zsolt Talata</a></li>
<li>CS/AI RL control <a href="https://hashemi.ku.edu/">Morteza Hashemi</a></li>
</ul></li>
<li><p><a href="https://webapp4.asu.edu/dgsadmissions/logout">Arizona State</a> Dec 1</p>

<ul>
<li>TODO: SOP</li>
<li>Faculty, SOP identify two or three ASU faculty with matching research interests. 
<ul>
<li><a href="https://scai.engineering.asu.edu/computer-science-and-engineering-faculty">Faculty list</a></li>
<li><a href="https://search.asu.edu/profile/95646">Subbarao Kambhampati</a> <a href="https://yochan-lab.github.io/papers/">web2</a>
<ul>
<li>Why Did You Do That? Generalizing Causal Link Explanations to Fully Observable Non-Deterministic Planning Problems</li>
<li>Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)</li>
</ul></li>
<li><a href="https://www.public.asu.edu/~ssriva43/">Siddharth Srivastava</a>
<ul>
<li>Learning Dynamic Abstract Representations for Sample-Efficient Reinforcement Learning.</li>
</ul></li>
<li><a href="https://search.asu.edu/profile/3410924">Dimitri Bertsekas</a>
<ul>
<li>'ExpertRNA: A new framework for RNA structure prediction'</li>
</ul></li>
<li>bio informatics <a href="https://search.asu.edu/profile/3505050">Heewook Lee</a></li>
<li>bio informatics <a href="https://search.asu.edu/profile/3182641">Stephanie Forrest</a></li>
</ul></li>
<li>Program
<ul>
<li><a href="https://degrees.apps.asu.edu/masters-phd/major/ASU00/ESCOMSCPHD/computer-science-phd?init=false&amp;nopassive=true">ASU program</a></li>
<li><a href="https://scai.engineering.asu.edu/wp-content/uploads/2022/08/PHD-CS-Handbook-2022-2023Publish.pdf">ASU handbook</a>
<ul>
<li>Comprehensive exam, show mastered the knowledge to conduct research in specialization</li>
<li>Proposal exam, mastered the research methods to identify, formulate, and plan research in specialization</li>
</ul></li>
</ul></li>
</ul></li>
<li><p><a href="https://delegated.osu.edu/psp/csosuda/EMPLOYEE/CAMP/c/OAD_GEA.OAD_GEA_NUR_APL.GBL?">Ohio State</a> Dec 1</p>

<ul>
<li>id: yechanhong92</li>
<li>TODO: SOP, faculty names</li>
<li><a href="https://cse.osu.edu/research/artificial-intelligence">Faculty</a>
<ul>
<li><a href="https://aperrault.github.io/publications/">Andrew Perrault</a>
<ul>
<li>'Normality-Guided Distributional Reinforcement Learning for Continuous Control'
<ul>
<li>We propose a different idea, leveraging the features of the learned distribution to estimate whether a state is sufficiently visited or not.
<ul>
<li>Sampling enough</li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="http://newslab.ece.ohio-state.edu/for%20students/index.html">Ness B. Shroff</a>
<ul>
<li>'Optimal Sampling for Data Freshness: Unreliable Transmissions with Random Two-way Delay'
<ul>
<li>optimal sampling strategy that minimizes the long-term average estimation error</li>
</ul></li>
</ul></li>
</ul></li>
<li>Program
<ul>
<li>Direct PhD track</li>
<li>Coursework (competant and knowledgeable on fundamental principles of cs) </li>
<li>and research</li>
<li>new qualifying process, take time to build the basics and faculty research assessment</li>
</ul></li>
<li>Course
<ul>
<li>STAT 7620 Elements of Statistical Learning, interdisciplinary final project to apply the ideas</li>
</ul></li>
</ul></li>
<li><p><a href="https://apply.grad.wisc.edu/Account/Login?ReturnUrl=%2f">Uni Wisconsin Madison</a> Dec 15</p>

<ul>
<li>https://www.cs.wisc.edu/graduate/graduate-admissions-faq/</li>
<li><p>faculty</p>

<ul>
<li>RL <a href="https://pages.cs.wisc.edu/~jphanna/publications.html">Josiah Hanna</a>
<ul>
<li>'Importance Sampling in Reinforcement Learning with an Estimated Behavior Policy'
<ul>
<li>By replacing behavior policy action probabilities with maximum likelihood estimates from observed data, reduce variance due to sampling error.</li>
</ul></li>
</ul></li>
<li>RL <a href="https://pages.cs.wisc.edu/~jerryzhu/research.html">Xiaojin Zhu</a>
<ul>
<li>'The Sample Complexity of Teaching-by-Reinforcement on Q-Learning'
<ul>
<li>characterize the sample complexity of teaching for different constraints in constructing teaching sequence</li>
<li>I raelly like this style of exploring consequences</li>
</ul></li>
</ul></li>
<li>statistics: <a href="https://pages.stat.wisc.edu/~miaoyan/people.html">Miaoyan Wang</a></li>
<li>bio <a href="https://www.biostat.wisc.edu/~vsingh/">Vikas Singh</a></li>
<li><a href="http://www.iliasdiakonikolas.org/">Ilias Diakonikolas</a></li>
<li>statistics: <a href="https://pages.cs.wisc.edu/~raskutti/publication.html">Garvesh Raskutti</a></li>
<li>Daifeng Wang</li>
</ul></li>
<li><p>TODO: add Robert Nowak</p></li>
<li>SOP why this school is for you
<ul>
<li>faculty research</li>
<li>courses
  * CS761 Mathematical Foundations of Machine Learning
    * foundations fo statistics, final project to make small contribution to jumpstart the research process.</li>
<li>program characteristic
<ul>
<li>Well balanced</li>
<li>breadth requirement, take courese, passing qualifying examination
<ul>
<li>Artificial Intelligence: 532, 534, 540, 545, 731, 760, 761, 766, 769</li>
<li>Bioinformatics: 576,776</li>
</ul></li>
<li>depth requirement: preliminary examination</li>
</ul></li>
</ul></li>
</ul></li>

<li><p><a href="https://grad.apply.colorado.edu/account/login">University of Colorado Boulder</a> Dec 15</p>

<ul>
<li><p><a href="https://www.colorado.edu/cs/admissions/graduate-admissions/how-apply">Statement of Purpose</a></p>

<ul>
<li>Colorado doesn't have a seperate section for indicating interest to program so you need to be really clear in this section.</li>
<li>Section headers</li>
</ul></li>
<li><p><a href="https://www.colorado.edu/cs/admissions/graduate-admissions/see-who-recruiting-fall-2023">recruiting</a></p></li>
<li><a href="https://www.colorado.edu/cs/academics/graduate-programs/doctor-philosophy/degree-requirements">requirements</a></li>
<li>RL Control Systems <a href="https://www.hyconsys.com/publications.html">Majid Zamani</a></li>
<li>RL <a href="https://spot.colorado.edu/~lich1539/">Lijun Chen</a></li>
<li>RL <a href="https://astrivedi.github.io/www/pubs.html">Ashutosh Trivedi</a></li>
<li>SOP why this school is for you, just list of professors
<ul>
<li>Professor Lijun Chen's research, 'Incentivized Exploration for Multi-Armed Bandits under Reward Drift', provides ideas related to my key question of qualifying different types of sampling; the paper explores a compensation scheme for UCB, e-Greedy, and Thompson sampling algorithms and demonstrates it's effectiveness by show the regret is similar to the compensation. I really appreciated the style of the paper where the theory was backed up with numerical experiments.</li>
<li>Professor Majid Zamani's research, 'Compositional construction of finite MDPs for large-scale stochastic switched systems: A dissipativity approach', constructs an estimation and establishes an upper bound for the error. I am very interested in these types of techniques of simplifying a more complex system and qualifying the simplication.</li>
<li>I am also intrested in the statistical machine learning research from the mathematics department; professor Jem Corcoran's research on using importance sampling to manage rare event probabilities partially answers my key questions on how sampling and computational effectiveness.</li>
<li>I am looking forward to taking required coursework such as Probabilistic Models of Human and Machine Learning mathematical background and plenty of practical experience neccesary to start research.</li>
</ul></li>
</ul></li>
</ul>

</div></body> </html>
