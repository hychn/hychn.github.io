<!DOCTYPE html><html><head><title>todo</title><meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" /><meta http-equiv="Pragma" content="no-cache" /><meta http-equiv="Expires" content="0" /><link rel = "stylesheet" type = "text/css" href = "https://hychn.github.io/style.css" /><meta name="viewport" content="width=device-width, initial-scale=1" /><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://hychn.github.io/tbl_contents.js"></script> </head> <body style="background-color:white;"> <div class="top"><button onclick="toggle_show()">Table of Contents</button> <button onclick="toggle_show_spoiler()">Toggle Spoiler</button>  <button onclick="scroll_bottom()">GOTO END</button> <div id="toc_frame"> <div id="toc"></div> </div> </div>   <div id="contents">
<ul>
<li>Need to learn the classical algorithms like A3C, spinningup </li>
<li><a href="http://www.incompleteideas.net/book/ebook/the-book.html">RL The book</a></li>
<li>All of Statistics: A Concise Course in Statistical Inference</li>
<li>Proofs from THE BOOK</li>
</ul>

<h1>RL Questions</h1>

<ul>
<li>On policy vs Off Policy meaning?</li>
<li><a href="http://www.incompleteideas.net/book/ebook/node66.html">actor–critic</a>
<ul>
<li>"Policy-based methods such as the asynchronous advantage actor–critic (A3C) algorithm combine a deep neural network with the actor–critic framework."</li>
</ul></li>
<li>Temporal difference (TD) learning refers to a class of model-free reinforcement learning methods which learn by bootstrapping from the current estimate of the value function</li>
</ul>

</div></body> </html>
